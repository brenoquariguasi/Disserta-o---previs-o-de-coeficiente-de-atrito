{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando todas as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o banco de dados\n",
    "dados = np.genfromtxt('Dados.csv', delimiter=';', skip_header=1)\n",
    "dados = np.delete(dados, [5, 6], axis=1) # Excluindo as variáveis de tráfego \"Operacoes_medicoes\" e \"Operacoes_anual\"\n",
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o conjunto de dados de entrada, X, e de saída, Y\n",
    "X, Y = dados[:, :6], dados[:, 6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os conjuntos de dados entre 90% para Treinamento e 10% para Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "print('Shape X_train:', X_train.shape)\n",
    "print('Shape X_test:', X_test.shape)\n",
    "print('Shape y_train:', y_train.shape)\n",
    "print('Shape y_test:', y_test.shape)\n",
    "\n",
    "# Mais informações sobre a divisão de dados train_test_split: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando o pré-processamento de Standard Scaler\n",
    "\\begin{equation}\n",
    "\tz = \\frac{(x - \\overline{x})}{s}\n",
    "\\end{equation}\n",
    "$z$: valor normalizado;<br>\n",
    "$x$: valor a ser normalizado;<br>\n",
    "$\\overline{x}$: média;<br>\n",
    "$s$: desvio padrão.\n",
    "\n",
    "Fonte: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processando os dados de entrada utilizando o pré-processamento Standard Scaler\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(X_train) # Ajustando os dados para a média e desvio padrão do conjunto de teste\n",
    "X_train = scaler_x.transform(X_train) # Aplicando a transformação no conjunto de treinamento\n",
    "X_test = scaler_x.transform(X_test) # O conjunto de teste é pré-processado de acordo com o conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breve estatística descritiva do conjunto de treinamento\n",
    "print('X_train min: {:.2f}'.format(X_train[:,0].min()), ', X_train min: {:.2f}'.format(X_train[:,0].max()), ', X_train média: {:.2}'.format(X_train[:,0].mean()), 'e X_train desv. pad.: {:.2f}'.format(X_train[:,0].std()))\n",
    "print('X_train min: {:.2f}'.format(X_train[:,1].min()), ', X_train min: {:.2f}'.format(X_train[:,1].max()), ', X_train média: {:.2f}'.format(X_train[:,1].mean()), 'e X_train desv. pad.: {:.2f}'.format(X_train[:,1].std()))\n",
    "print('X_train min: {:.2f}'.format(X_train[:,2].min()), ', X_train min: {:.2f}'.format(X_train[:,2].max()), ', X_train média: {:.2f}'.format(X_train[:,2].mean()), 'e X_train desv. pad.: {:.2f}'.format(X_train[:,2].std()))\n",
    "print('X_train min: {:.2f}'.format(X_train[:,3].min()), ', X_train min: {:.2f}'.format(X_train[:,3].max()), ', X_train média: {:.2f}'.format(X_train[:,3].mean()), 'e X_train desv. pad.: {:.2f}'.format(X_train[:,3].std()))\n",
    "print('X_train min: {:.2f}'.format(X_train[:,4].min()), ', X_train min: {:.2f}'.format(X_train[:,4].max()), ', X_train média: {:.2f}'.format(X_train[:,4].mean()), 'e X_train desv. pad.: {:.2f}'.format(X_train[:,4].std()))\n",
    "print('X_train min: {:.2f}'.format(X_train[:,5].min()), ', X_train min: {:.2f}'.format(X_train[:,5].max()), ', X_train média: {:.2f}'.format(X_train[:,5].mean()), 'e X_train desv. pad.: {:.2f}'.format(X_train[:,5].std()))      \n",
    "print('y_train min: {:.2f}'.format(y_train.min()), ', y_train min: {:.2f}'.format(y_train.max()), ', y_train média: {:.2f}'.format(y_train.mean()), 'e y_train desv. pad.: {:.2f}'.format(y_train.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breve estatística descritiva do conjunto de teste\n",
    "print('X_test min: {:.2f}'.format(X_test[:,0].min()), ', X_test min: {:.2f}'.format(X_test[:,0].max()), ', X_test média: {:.2}'.format(X_test[:,0].mean()), 'e X_test desv. pad.: {:.2f}'.format(X_test[:,0].std()))\n",
    "print('X_test min: {:.2f}'.format(X_test[:,1].min()), ', X_test min: {:.2f}'.format(X_test[:,1].max()), ', X_test média: {:.2f}'.format(X_test[:,1].mean()), 'e X_test desv. pad.: {:.2f}'.format(X_test[:,1].std()))\n",
    "print('X_test min: {:.2f}'.format(X_test[:,2].min()), ', X_test min: {:.2f}'.format(X_test[:,2].max()), ', X_test média: {:.2f}'.format(X_test[:,2].mean()), 'e X_test desv. pad.: {:.2f}'.format(X_test[:,2].std()))\n",
    "print('X_test min: {:.2f}'.format(X_test[:,3].min()), ', X_test min: {:.2f}'.format(X_test[:,3].max()), ', X_test média: {:.2f}'.format(X_test[:,3].mean()), 'e X_test desv. pad.: {:.2f}'.format(X_test[:,3].std()))\n",
    "print('X_test min: {:.2f}'.format(X_test[:,4].min()), ', X_test min: {:.2f}'.format(X_test[:,4].max()), ', X_test média: {:.2f}'.format(X_test[:,4].mean()), 'e X_test desv. pad.: {:.2f}'.format(X_test[:,4].std()))\n",
    "print('X_test min: {:.2f}'.format(X_test[:,5].min()), ', X_test min: {:.2f}'.format(X_test[:,5].max()), ', X_test média: {:.2f}'.format(X_test[:,5].mean()), 'e X_test desv. pad.: {:.2f}'.format(X_test[:,5].std()))      \n",
    "print('y_test min: {:.2f}'.format(y_test.min()), ', y_test min: {:.2f}'.format(y_test.max()), ', y_test média: {:.2f}'.format(y_test.mean()), 'e y_test desv. pad.: {:.2f}'.format(y_test.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado o *Multilayer Perceptron Regressor (MLP Regressor)* da biblioteca Scikit-Learn para o desenvolvimento dos modelos\n",
    "\n",
    "Mais informações sobre o MLP Regressor podem ser encontradas na página: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando 1 camada oculta\n",
    "Neurônios: 1 a 100<br>\n",
    "Função de ativação: ReLU<br>\n",
    "Solver: lbfgs<br>\n",
    "Alpha: 0.003, 0.01, 0.03, 0.3, 0.5<br>\n",
    "Nº máx. de iterações: 1.000<br>\n",
    "Random state: 0 a 11 (inicialização aleatória dos pesos)<br>\n",
    "NOTA: o hiperparâmetro **Random state** possibilita reproduzir exatamente os mesmos resultados alcançados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta célula são feitas 3 iterações simultâneas:\n",
    "# i) neurônios na 1ª camada oculta;\n",
    "# ii) alpha;\n",
    "# iii) random state.\n",
    "\n",
    "inicio_1_alpha = time.time()\n",
    "\n",
    "# As variáveis em que serão armazenadas os resultados e os hiperparâmetros da RNA são inicialmente apagadas, para evitar junção passados com novos\n",
    "\n",
    "# Treinamento\n",
    "armazenando_score_train_alpha = []  # Taxa de acerto do treinamento\n",
    "\n",
    "armazenando_mse_train_alpha = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_train_alpha = []  # Cálculo do Erro Absoluto Médio do treinamento\n",
    "\n",
    "\n",
    "# Teste\n",
    "armazenando_score_test_alpha = []  # Taxa de acerto do teste\n",
    "\n",
    "armazenando_mse_test_alpha = []  # Cáculo do Erro Quadrático Médio do teste\n",
    "\n",
    "armazenando_abs_error_test_alpha = []  # Cálculo do Erro Absoluto Médio do teste\n",
    "\n",
    "# Arquitetura da rede\n",
    "estrutura_1_alpha = []  # Neurônios na primeira camada oculta\n",
    "\n",
    "alpha_relu = [] # Alphas da rede\n",
    "\n",
    "random_state = [] # Inicialização dos pesos\n",
    "\n",
    "for i in range(1, 101):  # Iteração entre 1 a 100 neurônios em uma camada oculta\n",
    "    for k in [0.003, 0.01, 0.03, 0.3, 0.5]:\n",
    "        for z in range(0, 11):\n",
    "            reg_1 = MLPRegressor(\n",
    "            hidden_layer_sizes=(i,),\n",
    "            activation='relu',\n",
    "            solver='lbfgs',\n",
    "            alpha=k,\n",
    "            batch_size='auto',\n",
    "            learning_rate='adaptive',\n",
    "            learning_rate_init=0.4,\n",
    "            random_state=z,\n",
    "            max_iter=1000)\n",
    "    \n",
    "            reg_1.fit(X_train, y_train.ravel())\n",
    "    \n",
    "            armazenando_score_train_alpha = np.append(armazenando_score_train_alpha, reg_1.score(X_train, y_train))\n",
    "    \n",
    "            armazenando_mse_train_alpha = np.append(armazenando_mse_train_alpha, mean_squared_error(y_train, reg_1.predict(X_train)))\n",
    "    \n",
    "            armazenando_abs_error_train_alpha = np.append(armazenando_abs_error_train_alpha, mean_absolute_error(y_train, reg_1.predict(X_train)))\n",
    "    \n",
    "            armazenando_score_test_alpha = np.append(armazenando_score_test_alpha, reg_1.score(X_test, y_test))\n",
    "    \n",
    "            armazenando_mse_test_alpha = np.append(armazenando_mse_test_alpha, mean_squared_error(y_test, reg_1.predict(X_test)))\n",
    "    \n",
    "            armazenando_abs_error_test_alpha = np.append(armazenando_abs_error_test_alpha, mean_absolute_error(y_test, reg_1.predict(X_test)))\n",
    "    \n",
    "            fim_1_alpha = time.time()\n",
    "    \n",
    "            estrutura_1_alpha = np.append(estrutura_1_alpha, i)\n",
    "    \n",
    "            alpha_relu = np.append(alpha_relu, k)\n",
    "        \n",
    "            random_state = np.append(random_state, z)\n",
    "    \n",
    "print('Tempo de execução: {:.2f}s'.format(fim_1_alpha - inicio_1_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando os melhores resultados\n",
    "print('Score treinamento: {0:2.2f}'.format(armazenando_score_train_alpha.max()*100))\n",
    "print('MSE treinamento: {0:1.3f}'.format(armazenando_mse_train_alpha.min()))\n",
    "print('Erro médio absoluto treinamento: {0:1.3f}'.format(armazenando_abs_error_train_alpha.min()))\n",
    "print('Score teste: {0:2.2f}'.format(armazenando_score_test_alpha.max()*100))\n",
    "print('MSE teste: {0:1.3f}'.format(armazenando_mse_test_alpha.min()))\n",
    "print('Erro médio absoluto teste: {0:1.3f}'.format(armazenando_abs_error_test_alpha.min()))\n",
    "# Nota: o melhor resultado de Score treinamento não necessariamente corresponde a mesma arquitetura de melhor resultado de Score teste      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em arquivo .TXT onde é possível verificar qual arquitetura apresentou os melhores resultados\n",
    "np.savetxt('resultados_std_1_camada_relu_Operacoes_remocoes_alpha_0.003_0.01_0.03_0.3_0.5.txt', \n",
    "           np.c_[estrutura_1_alpha,\n",
    "                 random_state,\n",
    "                 alpha_relu,\n",
    "                 armazenando_score_train_alpha, \n",
    "                 armazenando_mse_train_alpha, \n",
    "                 armazenando_abs_error_train_alpha, \n",
    "                 armazenando_score_test_alpha, \n",
    "                 armazenando_mse_test_alpha, \n",
    "                 armazenando_abs_error_test_alpha],\n",
    "          header='estrutura_1 random_state alpha_relu armazenando_score_train_alpha armazenando_mse_train_alpha armazenando_abs_error_train_alpha armazenando_score_test_alpha armazenando_mse_test_alpha armazenando_abs_error_test_alpha')core_train armazenando_mse_train armazenando_abs_error_train armazenando_score_test armazenando_mse_test armazenando_abs_error_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando 2 camadas\n",
    "Neurônios na 1ª camada oculta: 1 a 100<br>\n",
    "Neurônios na 2ª camada oculta: 1 a 100<br>\n",
    "Função de ativação: ReLU<br>\n",
    "Solver: lbfgs<br>\n",
    "Alpha: 0.01, 0.1<br>\n",
    "Nº máx. de iterações: 1.000<br>\n",
    "Random state: 0 a 10 (inicialização de pesos)<br>\n",
    "**ATENÇÃO: A execução da célula abaixo demanda muito tempo (aproximadamente 7,5 dias)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta célula são feitas 4 iterações simultâneas:\n",
    "# i) neurônios na 1ª camada oculta;\n",
    "# ii) neurônios na 2ª camada oculta;\n",
    "# iii) alpha;\n",
    "# iv) random state.\n",
    "\n",
    "inicio_2_relu_alpha = time.time()\n",
    "\n",
    "# Treinamento\n",
    "armazenando_score_train_2_relu_alpha = []  # Taxa de acerto do treinamento\n",
    "\n",
    "armazenando_mse_train_2_relu_alpha = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_train_2_relu_alpha = []  # Cálculo do Erro Absoluto Médio do treinamento\n",
    "\n",
    "\n",
    "# Teste\n",
    "armazenando_score_test_2_relu_alpha = []  # Taxa de acerto do teste\n",
    "\n",
    "armazenando_mse_test_2_relu_alpha = []  # Cáculo do Erro Quadrático Médio do teste\n",
    "\n",
    "armazenando_abs_error_test_2_relu_alpha = []  # Cálculo do Erro Absoluto Médio do teste\n",
    "\n",
    "# Arquitetura da rede\n",
    "neuronios_cam_1_alpha = []  # Neurônios na primeira camada oculta\n",
    "\n",
    "neuronios_cam_2_alpha = []  # Neurônios na segunda camada oculta\n",
    "\n",
    "alpha_relu_2 = []\n",
    "\n",
    "random_state = []\n",
    "\n",
    "for i in range(1, 101):  # Iteração entre 1 a 100 neurônios em uma camada oculta\n",
    "    for k in range(1, 101):  # Iteração entre 1 a 100 neurônios na segunda camada oculta\n",
    "        for j in [0.01, 0.1]:\n",
    "            for z in range(0, 10):\n",
    "                reg_2 = MLPRegressor(\n",
    "                hidden_layer_sizes=(i, k),\n",
    "                activation='relu',\n",
    "                solver='lbfgs',\n",
    "                alpha=j,\n",
    "                batch_size='auto',\n",
    "                learning_rate='adaptive',\n",
    "                learning_rate_init=0.4,\n",
    "                random_state=z,\n",
    "                max_iter=1000)\n",
    "        \n",
    "                reg_2.fit(X_train, y_train.ravel())\n",
    "        \n",
    "                armazenando_score_train_2_relu_alpha = np.append(armazenando_score_train_2_relu_alpha, reg_2.score(X_train, y_train))\n",
    "        \n",
    "                armazenando_mse_train_2_relu_alpha = np.append(armazenando_mse_train_2_relu_alpha, mean_squared_error(y_train, reg_2.predict(X_train)))\n",
    "        \n",
    "                armazenando_abs_error_train_2_relu_alpha = np.append(armazenando_abs_error_train_2_relu_alpha, mean_absolute_error(y_train, reg_2.predict(X_train)))\n",
    "        \n",
    "                armazenando_score_test_2_relu_alpha = np.append(armazenando_score_test_2_relu_alpha, reg_2.score(X_test, y_test))\n",
    "        \n",
    "                armazenando_mse_test_2_relu_alpha = np.append(armazenando_mse_test_2_relu_alpha, mean_squared_error(y_test, reg_2.predict(X_test)))\n",
    "        \n",
    "                armazenando_abs_error_test_2_relu_alpha = np.append(armazenando_abs_error_test_2_relu_alpha, mean_absolute_error(y_test, reg_2.predict(X_test)))\n",
    "        \n",
    "                fim_2_relu_alpha = time.time()\n",
    "        \n",
    "                neuronios_cam_1_alpha = np.append(neuronios_cam_1_alpha, i)\n",
    "        \n",
    "                neuronios_cam_2_alpha = np.append(neuronios_cam_2_alpha, k)\n",
    "            \n",
    "                alpha_relu_2 = np.append(alpha_relu_2, j)\n",
    "        \n",
    "                random_state = np.append(random_state, z)\n",
    "        \n",
    "print('Tempo de execução: %.2fs' %(fim_2_relu_alpha - inicio_2_relu_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando os melhores resultados\n",
    "print('Score treinamento: {0:2.2f}'.format(armazenando_score_train_2_relu_alpha.max()*100))\n",
    "print('MSE treinamento: {0:1.3f}'.format(armazenando_mse_train_2_relu_alpha.min()))\n",
    "print('Erro médio absoluto treinamento: {0:1.3f}'.format(armazenando_abs_error_train_2_relu_alpha.min()))\n",
    "print('Score teste: {0:2.2f}'.format(armazenando_score_test_2_relu_alpha.max()*100))\n",
    "print('MSE teste: {0:1.3f}'.format(armazenando_mse_test_2_relu_alpha.min()))\n",
    "print('Erro médio absoluto teste: {0:1.3f}'.format(armazenando_abs_error_test_2_relu_alpha.min()))\n",
    "# Nota: o melhor resultado de Score treinamento não necessariamente corresponde a mesma arquitetura de melhor resultado de Score teste      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em arquivo .TXT onde é possível verificar qual arquitetura apresentou os melhores resultados\n",
    "np.savetxt('resultados_std_2_camada_relu_Operacoes_remocoes_alpha.txt', \n",
    "           np.c_[neuronios_cam_1_alpha,\n",
    "                 neuronios_cam_2_alpha,\n",
    "                 alpha_relu_2,\n",
    "                 random_state,\n",
    "                 armazenando_score_train_2_relu_alpha, \n",
    "                 armazenando_mse_train_2_relu_alpha, \n",
    "                 armazenando_abs_error_train_2_relu_alpha, \n",
    "                 armazenando_score_test_2_relu_alpha, \n",
    "                 armazenando_mse_test_2_relu_alpha, \n",
    "                 armazenando_abs_error_test_2_relu_alpha],\n",
    "           comments='2camadas_2_100_e_1_100_alpha_0.01_0.1_random_state_0_10',\n",
    "          header='neuronios_cam_1_alpha neuronios_cam_2_alpha alpha_relu_2 random_state armazenando_score_train_2_relu_alpha armazenando_mse_train_2_relu_alpha armazenando_abs_error_train_2_relu_alpha armazenando_score_test_2_relu_alpha armazenando_mse_test_2_relu_alpha armazenando_abs_error_test_2_relu_alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando 1 camada\n",
    "Neurônios na 1ª camada oculta: 1 a 100<br>\n",
    "Função de ativação: Tanh<br>\n",
    "Solver: lbfgs<br>\n",
    "Alpha: 0.1<br>\n",
    "Nº máx. de iterações: 1.000<br>\n",
    "Random state: 0 a 10 (inicialização de pesos)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta célula são feitas 2 iterações simultâneas:\n",
    "# i) neurônios na 1ª camada oculta;\n",
    "# ii) random state.\n",
    "\n",
    "inicio_1_tanh = time.time()\n",
    "\n",
    "# Treinamento\n",
    "armazenando_score_train_1_tanh = []  # Taxa de acerto do treinamento\n",
    "\n",
    "armazenando_mse_train_1_tanh = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_train_1_tanh = []  # Cálculo do Erro Absoluto Médio do treinamento\n",
    "\n",
    "\n",
    "# Teste\n",
    "armazenando_score_test_1_tanh = []  # Taxa de acerto do teste\n",
    "\n",
    "armazenando_mse_test_1_tanh = []  # Cáculo do Erro Quadrático Médio do teste\n",
    "\n",
    "armazenando_abs_error_test_1_tanh = []  # Cálculo do Erro Absoluto Médio do teste\n",
    "\n",
    "# Arquitetura da rede\n",
    "estrutura_1_tanh = []  # Neurônios na primeira camada oculta\n",
    "\n",
    "i = []\n",
    "\n",
    "random_state = []\n",
    "\n",
    "for i in range(1, 101):  # Iteração entre 1 a 100 neurônios em uma camada oculta\n",
    "    for k in range(0, 11):\n",
    "        reg_1_tanh = MLPRegressor(\n",
    "        hidden_layer_sizes=(i,),\n",
    "        activation='tanh',\n",
    "        solver='lbfgs',\n",
    "        alpha=0.1,\n",
    "        batch_size='auto',\n",
    "        learning_rate='adaptive',\n",
    "        learning_rate_init=0.4,\n",
    "        random_state=k,\n",
    "        max_iter=1000)\n",
    "    \n",
    "        reg_1_tanh.fit(X_train, y_train.ravel())\n",
    "    \n",
    "        armazenando_score_train_1_tanh = np.append(armazenando_score_train_1_tanh, reg_1_tanh.score(X_train, y_train))\n",
    "    \n",
    "        armazenando_mse_train_1_tanh = np.append(armazenando_mse_train_1_tanh, mean_squared_error(y_train, reg_1_tanh.predict(X_train)))\n",
    "    \n",
    "        armazenando_abs_error_train_1_tanh = np.append(armazenando_abs_error_train_1_tanh, mean_absolute_error(y_train, reg_1_tanh.predict(X_train)))\n",
    "    \n",
    "        armazenando_score_test_1_tanh = np.append(armazenando_score_test_1_tanh, reg_1_tanh.score(X_test, y_test))\n",
    "    \n",
    "        armazenando_mse_test_1_tanh = np.append(armazenando_mse_test_1_tanh, mean_squared_error(y_test, reg_1_tanh.predict(X_test)))\n",
    "    \n",
    "        armazenando_abs_error_test_1_tanh = np.append(armazenando_abs_error_test_1_tanh, mean_absolute_error(y_test, reg_1_tanh.predict(X_test)))\n",
    "    \n",
    "        fim_1_tanh = time.time()\n",
    "    \n",
    "        estrutura_1_tanh = np.append(estrutura_1_tanh, i)\n",
    "        \n",
    "        random_state = np.append(random_state, k)\n",
    "    \n",
    "print('Tempo de execução: {0:2.2f}s'.format(fim_1_tanh - inicio_1_tanh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando os melhores resultados\n",
    "print('Score treinamento: {0:2.2f}'.format(armazenando_score_train_1_tanh.max()*100))\n",
    "print('MSE treinamento: {0:1.3f}'.format(armazenando_mse_train_1_tanh.min()))\n",
    "print('Erro médio absoluto treinamento: {0:1.3f}'.format(armazenando_abs_error_train_1_tanh.min()))\n",
    "print('Score teste: {0:2.2f}'.format(armazenando_score_test_1_tanh.max()*100))\n",
    "print('MSE teste: {0:1.3f}'.format(armazenando_mse_test_1_tanh.min()))\n",
    "print('Erro médio absoluto teste: {0:1.3f}'.format(armazenando_abs_error_test_1_tanh.min()))\n",
    "# Nota: o melhor resultado de Score treinamento não necessariamente corresponde a mesma arquitetura de melhor resultado de Score teste      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em arquivo .TXT onde é possível verificar qual arquitetura apresentou os melhores resultados\n",
    "np.savetxt('resultados_std_1_camada_tanh_Operacoes_remocoes.txt', \n",
    "           np.c_[estrutura_1_tanh,\n",
    "                 random_state,\n",
    "                 armazenando_score_train_1_tanh, \n",
    "                 armazenando_mse_train_1_tanh, \n",
    "                 armazenando_abs_error_train_1_tanh, \n",
    "                 armazenando_score_test_1_tanh, \n",
    "                 armazenando_mse_test_1_tanh, \n",
    "                 armazenando_abs_error_test_1_tanh],\n",
    "          header='estrutura_1_tanh random_state armazenando_score_train_1_tanh armazenando_mse_train_1_tanh armazenando_abs_error_train_1_tanh armazenando_score_test_1_tanh armazenando_mse_test_1_tanh armazenando_abs_error_test_1_tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando 2 camada\n",
    "Neurônios na 1ª camada oculta: 1 a 100<br>\n",
    "Função de ativação: Tanh<br>\n",
    "Solver: lbfgs<br>\n",
    "Alpha: 0.1<br>\n",
    "Nº máx. de iterações: 1.000<br>\n",
    "Random state: 0 (inicialização de pesos)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta célula são feitas 2 iterações simultâneas:\n",
    "# i) neurônios na 1ª camada oculta;\n",
    "# ii) neurônios na 2ª camada oculta.\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Treinamento\n",
    "armazenando_score_train_2 = []  # Taxa de acerto do treinamento\n",
    "\n",
    "armazenando_mse_train_2 = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_train_2 = []  # Cálculo do Erro Absoluto Médio do treinamento\n",
    "\n",
    "\n",
    "# Teste\n",
    "armazenando_score_test_2 = []  # Taxa de acerto do teste\n",
    "\n",
    "armazenando_mse_test_2 = []  # Cáculo do Erro Quadrático Médio do teste\n",
    "\n",
    "armazenando_abs_error_test_2 = []  # Cálculo do Erro Absoluto Médio do teste\n",
    "\n",
    "# Arquitetura da rede\n",
    "estrutura_2_neuronio_camada_1 = []  # Neurônios na primeira camada oculta\n",
    "\n",
    "estrutura_2_neuronio_camada_2 = []  # Neurônios na segunda camada oculta\n",
    "\n",
    "i = []\n",
    "\n",
    "k = []\n",
    "\n",
    "for i in range(1, 101):  # Iteração entre 1 a 100 neurônios na primeira camada oculta\n",
    "    for k in range(1, 101):  # Iteração entre 1 a 100 neurônios na segunda camada oculta\n",
    "        reg_2 = MLPRegressor(\n",
    "        hidden_layer_sizes=(k, i),\n",
    "        activation='tanh',\n",
    "        solver='lbfgs',\n",
    "        alpha=0.1,\n",
    "        batch_size='auto',\n",
    "        learning_rate='adaptive',\n",
    "        learning_rate_init=0.4,\n",
    "        random_state=0,\n",
    "        max_iter=1000)\n",
    "        \n",
    "        reg_2.fit(X_train, y_train.ravel())\n",
    "        \n",
    "        armazenando_score_train_2 = np.append(armazenando_score_train_2, reg_2.score(X_train, y_train))\n",
    "        \n",
    "        armazenando_mse_train_2 = np.append(armazenando_mse_train_2, mean_squared_error(y_train, reg_2.predict(X_train)))\n",
    "        \n",
    "        armazenando_abs_error_train_2 = np.append(armazenando_abs_error_train_2, mean_absolute_error(y_train, reg_2.predict(X_train)))\n",
    "        \n",
    "        armazenando_score_test_2 = np.append(armazenando_score_test_2, reg_2.score(X_test, y_test))\n",
    "        \n",
    "        armazenando_mse_test_2 = np.append(armazenando_mse_test_2, mean_squared_error(y_test, reg_2.predict(X_test)))\n",
    "        \n",
    "        armazenando_abs_error_test_2 = np.append(armazenando_abs_error_test_2, mean_absolute_error(y_test, reg_2.predict(X_test)))\n",
    "        \n",
    "        fim = time.time()\n",
    "        \n",
    "        estrutura_2_neuronio_camada_1 = np.append(estrutura_2_neuronio_camada_1, k)\n",
    "        \n",
    "        estrutura_2_neuronio_camada_2 = np.append(estrutura_2_neuronio_camada_2, i)\n",
    "        \n",
    "print('Tempo de execução: {0:10.2f}s'.format(fim - inicio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando os melhores resultados\n",
    "print('Score treinamento: {0:2.2f}'.format(armazenando_score_train_2.max()*100))\n",
    "print('MSE treinamento: {0:1.3f}'.format(armazenando_mse_train_2.min()))\n",
    "print('Erro médio absoluto treinamento: {0:1.3f}'.format(armazenando_abs_error_train_2.min()))\n",
    "print('Score teste: {0:2.2f}'.format(armazenando_score_test_2.max()*100))\n",
    "print('MSE teste: {0:1.3f}'.format(armazenando_mse_test_2.min()))\n",
    "print('Erro médio absoluto teste: {0:1.3f}'.format(armazenando_abs_error_test_2.min()))\n",
    "# Nota: o melhor resultado de Score treinamento não necessariamente corresponde a mesma arquitetura de melhor resultado de Score teste      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em arquivo .TXT onde é possível verificar qual arquitetura apresentou os melhores resultados\n",
    "np.savetxt('resultados_std_2_camada_tanh_Operacoes_remocoes.txt', \n",
    "           np.c_[estrutura_2_neuronio_camada_1,\n",
    "                 estrutura_2_neuronio_camada_2,\n",
    "                 armazenando_score_train_2, \n",
    "                 armazenando_mse_train_2, \n",
    "                 armazenando_abs_error_train_2, \n",
    "                 armazenando_score_test_2, \n",
    "                 armazenando_mse_test_2,\n",
    "                 armazenando_abs_error_test_2],\n",
    "          header='estrutura_2_neuronio_camada_1 estrutura_2_neuronio_camada_2 armazenando_score_train_2 armazenando_mse_train_2 armazenando_abs_error_train_2 armazenando_score_test_2 armazenando_mse_test_2 armazenando_mse_test_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando o pré-processamento MinMaxScaler\n",
    "\\begin{equation}\n",
    " z = \\frac{(x - x_\\textit{min}) \\times (d_2 - d_1)}{(x_\\textit{max} - x_\\textit{min})} + d_1\n",
    "\\end{equation}\n",
    "$z$: valor normalizado;\n",
    "\n",
    "$x$: valor a ser normalizado;\n",
    "\n",
    "$x_{max}$ e $x_{min}$: variação do valor de $x$;\n",
    "\n",
    "$d_1$ e $d_2$: limite ao qual o valor $x$ será reduzido.\n",
    "\n",
    "Fonte: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o cojunto de dados em 90% Treinamento e 10% Teste\n",
    "X_train_mms, X_test_mms, y_train_mms, y_test_mms = train_test_split(X, Y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados\n",
    "mms_x = MinMaxScaler()\n",
    "mms_y = MinMaxScaler()\n",
    "\n",
    "mms_x.fit(X_train_mms) # Ajustando os dados de entrada, X, para o conjunto de treinamento\n",
    "X_train_mms = mms_x.transform(X_train_mms) # Transformando o cojunto de dados de treinamento\n",
    "X_test_mms = mms_x.transform(X_test_mms) # Transformando o cojunto de dados de teste\n",
    "\n",
    "mms_y.fit(y_train_mms) # Ajustando os dados de saída, Y, para o conjunto de treinamento\n",
    "y_train_mms = mms_y.transform(y_train_mms) # Transformando o cojunto de dados de treinamento\n",
    "y_test_mms = mms_y.transform(y_test_mms) # Transformando o cojunto de dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatística descritiva dos dados de TREINAMENTO\n",
    "print('X_train_mms min: {:.2f}'.format(X_train_mms[:,0].min()), ', X_train_mms min: {:.2f}'.format(X_train_mms[:,0].max()), ', X_train_mms média: {:.2}'.format(X_train_mms[:,0].mean()), 'e X_train_mms desv. pad.: {:.2f}'.format(X_train_mms[:,0].std()))\n",
    "print('X_train_mms min: {:.2f}'.format(X_train_mms[:,1].min()), ', X_train_mms min: {:.2f}'.format(X_train_mms[:,1].max()), ', X_train_mms média: {:.2f}'.format(X_train_mms[:,1].mean()), 'e X_train_mms desv. pad.: {:.2f}'.format(X_train_mms[:,1].std()))\n",
    "print('X_train_mms min: {:.2f}'.format(X_train_mms[:,2].min()), ', X_train_mms min: {:.2f}'.format(X_train_mms[:,2].max()), ', X_train_mms média: {:.2f}'.format(X_train_mms[:,2].mean()), 'e X_train_mms desv. pad.: {:.2f}'.format(X_train_mms[:,2].std()))\n",
    "print('X_train_mms min: {:.2f}'.format(X_train_mms[:,3].min()), ', X_train_mms min: {:.2f}'.format(X_train_mms[:,3].max()), ', X_train_mms média: {:.2f}'.format(X_train_mms[:,3].mean()), 'e X_train_mms desv. pad.: {:.2f}'.format(X_train_mms[:,3].std()))\n",
    "print('X_train_mms min: {:.2f}'.format(X_train_mms[:,4].min()), ', X_train_mms min: {:.2f}'.format(X_train_mms[:,4].max()), ', X_train_mms média: {:.2f}'.format(X_train_mms[:,4].mean()), 'e X_train_mms desv. pad.: {:.2f}'.format(X_train_mms[:,4].std()))\n",
    "print('X_train_mms min: {:.2f}'.format(X_train_mms[:,5].min()), ', X_train_mms min: {:.2f}'.format(X_train_mms[:,5].max()), ', X_train_mms média: {:.2f}'.format(X_train_mms[:,5].mean()), 'e X_train_mms desv. pad.: {:.2f}'.format(X_train_mms[:,5].std()))      \n",
    "print('y_train_mms min: {:.2f}'.format(y_train_mms.min()), ', y_train_mms min: {:.2f}'.format(y_train_mms.max()), ', y_train_mms média: {:.2f}'.format(y_train_mms.mean()), 'e y_train_mms desv. pad.: {:.2f}'.format(y_train_mms.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatística descritiva dos dados de TESTE\n",
    "print('X_test_mms min: {:.2f}'.format(X_test_mms[:,0].min()), ', X_test_mms min: {:.2f}'.format(X_test_mms[:,0].max()), ', X_test_mms média: {:.2}'.format(X_test_mms[:,0].mean()), 'e X_test_mms desv. pad.: {:.2f}'.format(X_test_mms[:,0].std()))\n",
    "print('X_test_mms min: {:.2f}'.format(X_test_mms[:,1].min()), ', X_test_mms min: {:.2f}'.format(X_test_mms[:,1].max()), ', X_test_mms média: {:.2f}'.format(X_test_mms[:,1].mean()), 'e X_test_mms desv. pad.: {:.2f}'.format(X_test_mms[:,1].std()))\n",
    "print('X_test_mms min: {:.2f}'.format(X_test_mms[:,2].min()), ', X_test_mms min: {:.2f}'.format(X_test_mms[:,2].max()), ', X_test_mms média: {:.2f}'.format(X_test_mms[:,2].mean()), 'e X_test_mms desv. pad.: {:.2f}'.format(X_test_mms[:,2].std()))\n",
    "print('X_test_mms min: {:.2f}'.format(X_test_mms[:,3].min()), ', X_test_mms min: {:.2f}'.format(X_test_mms[:,3].max()), ', X_test_mms média: {:.2f}'.format(X_test_mms[:,3].mean()), 'e X_test_mms desv. pad.: {:.2f}'.format(X_test_mms[:,3].std()))\n",
    "print('X_test_mms min: {:.2f}'.format(X_test_mms[:,4].min()), ', X_test_mms min: {:.2f}'.format(X_test_mms[:,4].max()), ', X_test_mms média: {:.2f}'.format(X_test_mms[:,4].mean()), 'e X_test_mms desv. pad.: {:.2f}'.format(X_test_mms[:,4].std()))\n",
    "print('X_test_mms min: {:.2f}'.format(X_test_mms[:,5].min()), ', X_test_mms min: {:.2f}'.format(X_test_mms[:,5].max()), ', X_test_mms média: {:.2f}'.format(X_test_mms[:,5].mean()), 'e X_test_mms desv. pad.: {:.2f}'.format(X_test_mms[:,5].std()))      \n",
    "print('y_test_mms min: {:.2f}'.format(y_test_mms.min()), ', y_test_mms max: {:.2f}'.format(y_test_mms.max()), ', y_test_mms média: {:.2f}'.format(y_test_mms.mean()), 'e y_test_mms desv. pad.: {:.2f}'.format(y_test_mms.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando 1 camada\n",
    "Neurônios na 1ª camada oculta: 1 a 100<br>\n",
    "Função de ativação: Tanh<br>\n",
    "Solver: lbfgs<br>\n",
    "Alpha: 0.1<br>\n",
    "Nº máx. de iterações: 1.000<br>\n",
    "Random state: 0 a 9 (inicialização de pesos)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta célula são feitas 2 iterações simultâneas:\n",
    "# i) neurônios na 1ª camada oculta;\n",
    "# ii) random state.\n",
    "\n",
    "inicio_2 = time.time()\n",
    "\n",
    "# Treinamento\n",
    "armazenando_score_train_mms = []  # Taxa de acerto do treinamento\n",
    "\n",
    "armazenando_mse_train_mms = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_train_mms = []  # Cálculo do Erro Absoluto do treinamento\n",
    "\n",
    "\n",
    "# Teste\n",
    "armazenando_score_test_mms = []  # Taxa de acerto do teste\n",
    "\n",
    "armazenando_mse_test_mms = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_test_mms = []  # Cálculo do Erro Absoluto do treinamento\n",
    "\n",
    "# Arquitetura\n",
    "arquitetura_mms_1_tanh = []\n",
    "\n",
    "random_state = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    for k in range(0, 10):\n",
    "        reg_mms_1 = MLPRegressor(\n",
    "        hidden_layer_sizes=(i,),\n",
    "        activation='tanh',\n",
    "        solver='lbfgs',\n",
    "        alpha=0.1,\n",
    "        batch_size='auto',\n",
    "        learning_rate='adaptive',\n",
    "        learning_rate_init=0.4,\n",
    "        power_t=0.5,\n",
    "        max_iter=1000,\n",
    "        random_state=k,)\n",
    "    \n",
    "        reg_mms_1.fit(X_train_mms, y_train_mms.ravel())\n",
    "    \n",
    "        armazenando_score_train_mms = np.append(armazenando_score_train_mms, reg_mms_1.score(X_train_mms, y_train_mms))\n",
    "    \n",
    "        armazenando_mse_train_mms = np.append(armazenando_mse_train_mms, mean_squared_error(y_train_mms, reg_mms_1.predict(X_train_mms)))\n",
    "    \n",
    "        armazenando_abs_error_train_mms = np.append(armazenando_abs_error_train_mms, mean_absolute_error(y_train_mms, reg_mms_1.predict(X_train_mms)))\n",
    "    \n",
    "        armazenando_score_test_mms = np.append(armazenando_score_test_mms, reg_mms_1.score(X_test_mms, y_test_mms))\n",
    "    \n",
    "        armazenando_mse_test_mms = np.append(armazenando_mse_test_mms, mean_squared_error(y_test_mms, reg_mms_1.predict(X_test_mms)))\n",
    "    \n",
    "        armazenando_abs_error_test_mms = np.append(armazenando_abs_error_test_mms, mean_absolute_error(y_test_mms, reg_mms_1.predict(X_test_mms)))\n",
    "    \n",
    "        arquitetura_mms_1_tanh = np.append(arquitetura_mms_1_tanh, i)\n",
    "    \n",
    "        random_state = np.append(random_state, k)\n",
    "        \n",
    "        fim_2 = time.time()\n",
    "print('Tempo de execução: {0:2.2f}s'.format(fim_2 - inicio_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando os melhores resultados\n",
    "print('Score treinamento: {0:2.2f}'.format(armazenando_score_train_mms.max()*100))\n",
    "print('MSE treinamento: {0:1.3f}'.format(armazenando_mse_train_mms.min()))\n",
    "print('Erro médio absoluto treinamento: {0:1.3f}'.format(armazenando_abs_error_train_mms.min()))\n",
    "print('Score teste: {0:2.2f}'.format(armazenando_score_test_mms.max()*100))\n",
    "print('MSE teste: {0:1.3f}'.format(armazenando_mse_test_mms.min()))\n",
    "print('Erro médio absoluto teste: {0:1.3f}'.format(armazenando_abs_error_test_mms.min()))\n",
    "# Nota: o melhor resultado de Score treinamento não necessariamente corresponde a mesma arquitetura de melhor resultado de Score teste      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em arquivo .TXT onde é possível verificar qual arquitetura apresentou os melhores resultados\n",
    "np.savetxt('resultados_mms_1_camada_tanh.txt', \n",
    "           np.c_[arquitetura_mms_1_tanh,\n",
    "                 random_state,\n",
    "                 armazenando_score_train_mms, \n",
    "                 armazenando_mse_train_mms, \n",
    "                 armazenando_abs_error_train_mms, \n",
    "                 armazenando_score_test_mms, \n",
    "                 armazenando_mse_test_mms, \n",
    "                 armazenando_abs_error_test_mms],\n",
    "          header='arquitetura_mms_1_tanh random_state armazenando_score_train_mms armazenando_mse_train_mms armazenando_abs_error_train_mms armazenando_score_test_mms armazenando_mse_test_mms armazenando_abs_error_test_mms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando 2 camadas\n",
    "Neurônios na 1ª camada oculta: 1 a 100<br>\n",
    "Neurônios na 2ª camada oculta: 1 a 100<br>\n",
    "Função de ativação: Tanh<br>\n",
    "Solver: lbfgs<br>\n",
    "Alpha: 0.1<br>\n",
    "Nº máx. de iterações: 1.000<br>\n",
    "Random state: 0(inicialização de pesos)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta célula são feitas 2 iterações simultâneas:\n",
    "# i) neurônios na 1ª camada oculta;\n",
    "# ii) neurônios na 2ª camada oculta.\n",
    "\n",
    "inicio_3 = time.time()\n",
    "\n",
    "armazenando_fit_mms_2 = []\n",
    "\n",
    "#Treinamento\n",
    "armazenando_score_train_mms_2 = []  # Taxa de acerto do treinamento\n",
    "\n",
    "armazenando_mse_train_mms_2 = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_train_mms_2 = []  # Cálculo do Erro Absoluto do treinamento\n",
    "\n",
    "\n",
    "#Teste\n",
    "armazenando_score_test_mms_2 = []  # Taxa de acerto do teste\n",
    "\n",
    "armazenando_mse_test_mms_2 = []  # Cáculo do Erro Quadrático Médio do teste\n",
    "\n",
    "armazenando_abs_error_test_mms_2 = []  # Cálculo do Erro Absoluto do teste\n",
    "\n",
    "# Arquitetura\n",
    "arquitetura_mms_camada_1_tanh = []\n",
    "\n",
    "arquitetura_mms_camada_2_tanh = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    for k in range(1, 101):\n",
    "        reg = MLPRegressor(\n",
    "        hidden_layer_sizes=(k,i),\n",
    "        activation='tanh',\n",
    "        solver='lbfgs',\n",
    "        alpha=0.1,\n",
    "        batch_size='auto',\n",
    "        learning_rate='adaptive',\n",
    "        learning_rate_init=0.4,\n",
    "        power_t=0.5,\n",
    "        max_iter=1000,\n",
    "        random_state=0,)\n",
    "        \n",
    "        reg.fit(X_train_mms, y_train_mms.ravel())\n",
    "        \n",
    "        armazenando_score_train_mms_2 = np.append(armazenando_score_train_mms_2, reg.score(X_train_mms, y_train_mms))\n",
    "        \n",
    "        armazenando_mse_train_mms_2 = np.append(armazenando_mse_train_mms_2, mean_squared_error(y_train_mms, reg.predict(X_train_mms)))\n",
    "        \n",
    "        armazenando_abs_error_train_mms_2 = np.append(armazenando_abs_error_train_mms_2, mean_absolute_error(y_train_mms, reg.predict(X_train_mms)))\n",
    "        \n",
    "        armazenando_score_test_mms_2 = np.append(armazenando_score_test_mms_2, reg.score(X_test_mms, y_test_mms))\n",
    "        \n",
    "        armazenando_mse_test_mms_2 = np.append(armazenando_mse_test_mms_2, mean_squared_error(y_test_mms, reg.predict(X_test_mms)))\n",
    "        \n",
    "        armazenando_abs_error_test_mms_2 = np.append(armazenando_abs_error_test_mms_2, mean_absolute_error(y_test_mms, reg.predict(X_test_mms)))\n",
    "        \n",
    "        arquitetura_mms_camada_1_tanh = np.append(arquitetura_mms_camada_1_tanh, k)\n",
    "\n",
    "        arquitetura_mms_camada_2_tanh = np.append(arquitetura_mms_camada_2_tanh, i)\n",
    "        \n",
    "        fim_3 = time.time()\n",
    "print(fim_3 - inicio_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando os melhores resultados\n",
    "print('Score treinamento: {0:2.2f}'.format(armazenando_score_train_mms_2.max()*100))\n",
    "print('MSE treinamento: {0:1.3f}'.format(armazenando_mse_train_mms_2.max()))\n",
    "print('Erro médio absoluto treinamento: {0:1.3f}'.format(armazenando_abs_error_train_mms_2.max()))\n",
    "print('Score teste: {0:2.2f}'.format(armazenando_score_test_mms_2.max()*100))\n",
    "print('MSE teste: {0:1.3f}'.format(armazenando_mse_test_mms_2.max()))\n",
    "print('Erro médio absoluto teste: {0:1.3f}'.format(armazenando_abs_error_test_mms_2.max()))\n",
    "# Nota: o melhor resultado de Score treinamento não necessariamente corresponde a mesma arquitetura de melhor resultado de Score teste      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em arquivo .TXT onde é possível verificar qual arquitetura apresentou os melhores resultados\n",
    "np.savetxt('resultados_mms_2_camadas_tanh.txt', \n",
    "           np.c_[arquitetura_mms_camada_1_tanh,\n",
    "                 arquitetura_mms_camada_2_tanh,\n",
    "                 armazenando_score_train_mms_2, \n",
    "                 armazenando_mse_train_mms_2, \n",
    "                 armazenando_abs_error_train_mms_2, \n",
    "                 armazenando_score_test_mms_2, \n",
    "                 armazenando_mse_test_mms_2, \n",
    "                 armazenando_abs_error_test_mms_2],\n",
    "          header='arquitetura_mms_camada_1_tanh arquitetura_mms_camada_2_tanh armazenando_score_train_mms_2 armazenando_mse_train_mms_2 armazenando_abs_error_train_mms_2 armazenando_score_test_mms_2 armazenando_mse_test_mms_2 armazenando_abs_error_test_mms_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando 1 camada\n",
    "Neurônios na 1ª camada oculta: 1 a 100<br>\n",
    "Função de ativação: ReLU<br>\n",
    "Solver: lbfgs<br>\n",
    "Alpha: 0.1<br>\n",
    "Nº máx. de iterações: 1.000<br>\n",
    "Random state: 0 a 9(inicialização de pesos)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta célula são feitas 2 iterações simultâneas:\n",
    "# i) neurônios na 1ª camada oculta;\n",
    "# ii) random state.\n",
    "\n",
    "inicio_1_mms = time.time()\n",
    "\n",
    "# Treinamento\n",
    "armazenando_score_train_mms_1_relu = []  # Taxa de acerto do treinamento\n",
    "\n",
    "armazenando_mse_train_mms_1_relu = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_train_mms_1_relu = []  # Cálculo do Erro Absoluto do treinamento\n",
    "\n",
    "\n",
    "# Teste\n",
    "armazenando_score_test_mms_1_relu = []  # Taxa de acerto do teste\n",
    "\n",
    "armazenando_mse_test_mms_1_relu = []  # Cáculo do Erro Quadrático Médio do teste\n",
    "\n",
    "armazenando_abs_error_test_mms_1_relu = []  # Cálculo do Erro Absoluto do teste\n",
    "\n",
    "# Arquitetura\n",
    "neuronios_camada_1_mms = []\n",
    "\n",
    "random_state = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    for k in range(0, 10):\n",
    "        reg_mms_1_relu = MLPRegressor(\n",
    "        hidden_layer_sizes=(i,),\n",
    "        activation='relu',\n",
    "        solver='lbfgs',\n",
    "        alpha=0.1,\n",
    "        max_iter=1000,\n",
    "        random_state=k,)\n",
    "        reg_mms_1_relu.fit(X_train_mms, y_train_mms.ravel())\n",
    "    \n",
    "        armazenando_score_train_mms_1_relu = np.append(armazenando_score_train_mms_1_relu, reg_mms_1_relu.score(X_train_mms, y_train_mms))\n",
    "    \n",
    "        armazenando_mse_train_mms_1_relu = np.append(armazenando_mse_train_mms_1_relu, mean_squared_error(y_train_mms, reg_mms_1_relu.predict(X_train_mms)))\n",
    "    \n",
    "        armazenando_abs_error_train_mms_1_relu = np.append(armazenando_abs_error_train_mms_1_relu, mean_absolute_error(y_train_mms, reg_mms_1_relu.predict(X_train_mms)))\n",
    "    \n",
    "        armazenando_score_test_mms_1_relu = np.append(armazenando_score_test_mms_1_relu, reg_mms_1_relu.score(X_test_mms, y_test_mms))\n",
    "    \n",
    "        armazenando_mse_test_mms_1_relu = np.append(armazenando_mse_test_mms_1_relu, mean_squared_error(y_test_mms, reg_mms_1_relu.predict(X_test_mms)))\n",
    "    \n",
    "        armazenando_abs_error_test_mms_1_relu = np.append(armazenando_abs_error_test_mms_1_relu, mean_absolute_error(y_test_mms, reg_mms_1_relu.predict(X_test_mms)))\n",
    "        \n",
    "        neuronios_camada_1_mms = np.append(neuronios_camada_1_mms, i)\n",
    "        \n",
    "        random_state = np.append(random_state, k)\n",
    "        \n",
    "        fim_1_mms = time.time()\n",
    "print('Tempo de execução: %.2f' %(fim_1_mms - inicio_1_mms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando os melhores resultados\n",
    "print('Score treinamento: {0:2.2f}'.format(armazenando_score_train_mms_1_relu.max()*100))\n",
    "print('MSE treinamento: {0:1.3f}'.format(armazenando_mse_train_mms_1_relu.min()))\n",
    "print('Erro médio absoluto treinamento: {0:1.3f}'.format(armazenando_abs_error_train_mms_1_relu.min()))\n",
    "print('Score teste: {0:2.2f}'.format(armazenando_score_test_mms_1_relu.max()*100))\n",
    "print('MSE teste: {0:1.3f}'.format(armazenando_mse_test_mms_1_relu.min()))\n",
    "print('Erro médio absoluto teste: {0:1.3f}'.format(armazenando_abs_error_test_mms_1_relu.min()))\n",
    "# Nota: o melhor resultado de Score treinamento não necessariamente corresponde a mesma arquitetura de melhor resultado de Score teste      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em arquivo .TXT onde é possível verificar qual arquitetura apresentou os melhores resultados\n",
    "np.savetxt('resultados_mms_1_camada_relu.txt', \n",
    "           np.c_[neuronios_camada_1_mms,\n",
    "                 random_state,\n",
    "                 armazenando_score_train_mms_1_relu, \n",
    "                 armazenando_mse_train_mms_1_relu, \n",
    "                 armazenando_abs_error_train_mms_1_relu, \n",
    "                 armazenando_score_test_mms_1_relu, \n",
    "                 armazenando_mse_test_mms_1_relu, \n",
    "                 armazenando_abs_error_test_mms_1_relu],\n",
    "          header='neuronios_camada_1_mms random_state armazenando_score_train_mms_1_relu armazenando_mse_train_mms_1_relu armazenando_abs_error_train_mms_1_relu armazenando_score_test_mms_1_relu armazenando_mse_test_mms_1_relu armazenando_abs_error_test_mms_1_relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando 2 camadas\n",
    "Neurônios na 1ª camada oculta: 1 a 100<br>\n",
    "Neurônios na 2ª camada oculta: 1 a 100<br>\n",
    "Função de ativação: ReLU<br>\n",
    "Solver: lbfgs<br>\n",
    "Alpha: 0.01 e 0.3<br>\n",
    "Nº máx. de iterações: 1.000<br>\n",
    "Random state: 0 a 9(inicialização de pesos)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta célula são feitas 3 iterações simultâneas:\n",
    "# i) neurônios na 1ª camada oculta;\n",
    "# ii) neurônios na 2ª camada oculta;\n",
    "# ii) alpha.\n",
    "\n",
    "inicio_2_mms_relu = time.time()\n",
    "\n",
    "#Treinamento\n",
    "armazenando_score_train_mms_2_relu = []  # Taxa de acerto do treinamento\n",
    "\n",
    "armazenando_mse_train_mms_2_relu = []  # Cáculo do Erro Quadrático Médio do treinamento\n",
    "\n",
    "armazenando_abs_error_train_mms_2_relu = []  # Cálculo do Erro Absoluto do treinamento\n",
    "\n",
    "\n",
    "#Teste\n",
    "armazenando_score_test_mms_2_relu = []  # Taxa de acerto do teste\n",
    "\n",
    "armazenando_mse_test_mms_2_relu = []  # Cáculo do Erro Quadrático Médio do teste\n",
    "\n",
    "armazenando_abs_error_test_mms_2_relu = []  # Cálculo do Erro Absoluto do teste\n",
    "\n",
    "\n",
    "# Arquitetura\n",
    "neuronio_camada_1_mms_relu = []\n",
    "\n",
    "neuronio_camada_2_mms_relu = []\n",
    "\n",
    "alpha_mms_2_relu = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    for k in range(1, 101):\n",
    "        for z in [0.01, 0.3]:\n",
    "            reg_mms_2_relu = MLPRegressor(\n",
    "            hidden_layer_sizes=(i,k),\n",
    "            activation='relu',\n",
    "            solver='lbfgs',\n",
    "            alpha=z,\n",
    "            learning_rate='adaptive',\n",
    "            learning_rate_init=0.4,\n",
    "            max_iter=1000,\n",
    "            random_state=0,)\n",
    "    \n",
    "            reg_mms_2_relu.fit(X_train_mms, y_train_mms.ravel())\n",
    "        \n",
    "            armazenando_score_train_mms_2_relu = np.append(armazenando_score_train_mms_2_relu, reg_mms_2_relu.score(X_train_mms, y_train_mms))\n",
    "     \n",
    "            armazenando_mse_train_mms_2_relu = np.append(armazenando_mse_train_mms_2_relu, mean_squared_error(y_train_mms, reg_mms_2_relu.predict(X_train_mms)))\n",
    "            \n",
    "            armazenando_abs_error_train_mms_2_relu = np.append(armazenando_abs_error_train_mms_2_relu, mean_absolute_error(y_train_mms, reg_mms_2_relu.predict(X_train_mms)))\n",
    "    \n",
    "            armazenando_score_test_mms_2_relu = np.append(armazenando_score_test_mms_2_relu, reg_mms_2_relu.score(X_test_mms, y_test_mms))\n",
    "     \n",
    "            armazenando_mse_test_mms_2_relu = np.append(armazenando_mse_test_mms_2_relu, mean_squared_error(y_test_mms, reg_mms_2_relu.predict(X_test_mms)))\n",
    "    \n",
    "            armazenando_abs_error_test_mms_2_relu = np.append(armazenando_abs_error_test_mms_2_relu, mean_absolute_error(y_test_mms, reg_mms_2_relu.predict(X_test_mms)))\n",
    "    \n",
    "            fim_2_mms_relu = time.time()\n",
    "    \n",
    "            neuronio_camada_1_mms_relu = np.append(neuronio_camada_1_mms_relu, i)\n",
    "        \n",
    "            neuronio_camada_2_mms_relu = np.append(neuronio_camada_2_mms_relu, k)\n",
    "            \n",
    "            alpha_mms_2_relu = np.append(alpha_mms_2_relu, z)\n",
    "        \n",
    "print('Tempo de execução: %.2f' %(fim_2_mms_relu - inicio_2_mms_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando os melhores resultados\n",
    "print('Score treinamento: {0:2.2f}'.format(armazenando_score_train_mms_2_relu.max()*100))\n",
    "print('MSE treinamento: {0:1.3f}'.format(armazenando_mse_train_mms_2_relu.min()))\n",
    "print('Erro médio absoluto treinamento: {0:1.3f}'.format(armazenando_abs_error_train_mms_2_relu.min()))\n",
    "print('Score teste: {0:2.2f}'.format(armazenando_score_test_mms_2_relu.max()*100))\n",
    "print('MSE teste: {0:1.3f}'.format(armazenando_mse_test_mms_2_relu.min()))\n",
    "print('Erro médio absoluto teste: {0:1.3f}'.format(armazenando_abs_error_test_mms_2_relu.min()))\n",
    "# Nota: o melhor resultado de Score treinamento não necessariamente corresponde a mesma arquitetura de melhor resultado de Score teste      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados em arquivo .TXT onde é possível verificar qual arquitetura apresentou os melhores resultados\n",
    "np.savetxt('resultados_mms_2_camada_relu_alphas.txt', \n",
    "           np.c_[neuronio_camada_1_mms_relu,\n",
    "                 neuronio_camada_2_mms_relu,\n",
    "                 alpha_mms_2_relu,\n",
    "                 armazenando_score_train_mms_2_relu, \n",
    "                 armazenando_mse_train_mms_2_relu, \n",
    "                 armazenando_abs_error_train_mms_2_relu, \n",
    "                 armazenando_score_test_mms_2_relu, \n",
    "                 armazenando_mse_test_mms_2_relu, \n",
    "                 armazenando_abs_error_test_mms_2_relu],\n",
    "          header='neuronio_camada_1_mms_relu neuronio_camada_2_mms_relu alpha_mms_2_relu armazenando_score_train_mms_2_relu armazenando_mse_train_mms_2_relu armazenando_abs_error_train_mms_2_relu armazenando_score_test_mms_2_relu armazenando_mse_test_mms_2_relu armazenando_abs_error_test_mms_2_relu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
