{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BD 1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Coeficiente de atrito']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Temperatura_ensaio', \n",
    "         'Temperatura_AISWEB', \n",
    "         'Umidade_ensaio', \n",
    "         'Operacoes_anual',\n",
    "         'Operacoes_medicoes'], \n",
    "       axis=1,\n",
    "       inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ['Distancia', 'Macrotextura', 'Lado', 'Remocao', 'Idade_pavimento_meses', 'Umidade_AISWEB', 'Operacoes_remocoes']]\n",
    "Y = df['Coeficiente de atrito']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os conjuntos de dados entre 90% para Treinamento e 10% para Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "print('Shape X_train:', X_train.shape) # Imprime a matriz dos dados de entrada de treinamento\n",
    "print('Shape X_test:', X_test.shape) # Imprime a matriz dos dados de saída de treinamento\n",
    "print('Shape y_train:', y_train.shape) # Imprime a matriz dos dados de entrada de teste\n",
    "print('Shape y_test:', y_test.shape)  # Imprime a matriz dos dados de saída de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processando os dados de entrada utilizando o pré-processamento Standard Scaler\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(X_train) # Ajustando os dados para a média e desvio padrão do conjunto de teste\n",
    "X_train = pd.DataFrame(scaler_x.transform(X_train), columns=X.columns) # Aplicando a transformação no conjunto de treinamento\n",
    "X_test = pd.DataFrame(scaler_x.transform(X_test), columns=X.columns) # O conjunto de teste é pré-processado de acordo com o conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COM 1 CAMADA\n",
    "\n",
    "ativacao = ['logistic', 'tanh', 'relu'] # funções de ativação testadas\n",
    "menor_mae = 1 # o algoritmo começa a testar arquiteturas a partir de Erro Médio Absoluto de 1,00\n",
    "for i in np.arange(1, 100):\n",
    "    for j in ativacao:\n",
    "        for k in [0.01, 0.1, 0.5]:\n",
    "            reg = MLPRegressor(\n",
    "                        hidden_layer_sizes=(i),\n",
    "                        activation=j,\n",
    "                        solver='lbfgs',\n",
    "                        alpha=k,\n",
    "                        random_state=0,\n",
    "                        max_iter=500)\n",
    "            \n",
    "            reg.fit(X_train, y_train)\n",
    "            mae_teste = mean_absolute_error(y_test, reg.predict(X_test))\n",
    "            score_teste = reg.score(X_test, y_test)\n",
    "            print('i:%i', i, 'mae_teste: %.3f' %mae_teste, 'score_teste: %.2f' %(100*score_teste), 'f ativacao: %s' %j,'alpha: %.3f' %k)\n",
    "            if mae_teste < menor_mae:\n",
    "                menor_mae = mae_teste\n",
    "                neuronios_cam_1 = i\n",
    "                score_teste_melhor = score_teste*100\n",
    "                ativacao_1 = j\n",
    "                alpha = k\n",
    "\n",
    "# Salvando os resultados da Arquitetura com menor erro em um arquivo TXT                \n",
    "np.savetxt('resultados_c_macro_1cam.txt',\n",
    "           [menor_mae, neuronios_cam_1, \n",
    "            score_teste_melhor, \n",
    "            ativacao_1, \n",
    "            alpha],\n",
    "           fmt='%.5s',\n",
    "           header='menor_mae, neuronios_cam_1, score_teste_melhor, ativacao, alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COM 2 CAMADAS\n",
    "\n",
    "ativacao = ['logistic', 'tanh', 'relu'] # funções de ativação testadas\n",
    "menor_mae = 1 # o algoritmo começa a testar arquiteturas a partir de Erro Médio Absoluto de 1,00\n",
    "menor_mae = 1\n",
    "for i in np.arange(1, 100):\n",
    "    for y in np.arange(1, 100):\n",
    "        for j in ativacao:\n",
    "            for k in [0.01, 0.1, 0.5]:\n",
    "                reg = MLPRegressor(\n",
    "                            hidden_layer_sizes=(y, i),\n",
    "                            activation=j,\n",
    "                            solver='lbfgs',\n",
    "                            alpha=k,\n",
    "                            random_state=0,\n",
    "                            max_iter=500)\n",
    "                \n",
    "                reg.fit(X_train, y_train)\n",
    "                mae_teste = mean_absolute_error(y_test, reg.predict(X_test))\n",
    "                score_teste = reg.score(X_test, y_test)\n",
    "                print('y:', y, 'i:', i, 'mae_teste: %.3f' %mae_teste, 'score_teste: %.2f' %(100*score_teste), 'f ativacao: %s' %j,'alpha: %.3f' %k)\n",
    "                if mae_teste < menor_mae:\n",
    "                    menor_mae = mae_teste\n",
    "                    neuronios_cam_1 = y\n",
    "                    neuornios_cam_2 = i\n",
    "                    score_teste_melhor = score_teste*100\n",
    "                    ativacao_1 = j\n",
    "                    alpha = k\n",
    "        \n",
    "# Salvando os resultados da Arquitetura com menor erro em um arquivo TXT        \n",
    "np.savetxt('resultados_c_macro_2cam.txt',\n",
    "            [menor_mae, neuronios_cam_1, \n",
    "            neuornios_cam_2, \n",
    "            score_teste_melhor, \n",
    "            ativacao_1, \n",
    "            alpha],\n",
    "            fmt='%.5s',\n",
    "            header='menor_mae, neuronios_cam_1, neuronios_cam_2, score_teste_melhor, ativacao, alpha')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
